{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_classification_api.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyONmbDUBCJUOBVxmb9nYjCh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nada-Nasser/images-classification/blob/main/image_classification_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNbQcKlD3prh"
      },
      "source": [
        "pip install colabcode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XchERNpw4Smu",
        "outputId": "47f73d27-ed81-4ab2-8c41-9e65e3b5fd25"
      },
      "source": [
        "pip install torchvision\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu102)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.9.0+cu102)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchvision) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d8qp_Wp4Tmf",
        "outputId": "b05239fc-c88f-471d-ae43-a4b942d11301"
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11OpJW6g4Xps",
        "outputId": "f9f06ab1-03f0-4b92-c4c5-fb0da3fadc25"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Lasagne/Recipes/master/examples/resnet50/imagenet_classes.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-09 19:42:37--  https://raw.githubusercontent.com/Lasagne/Recipes/master/examples/resnet50/imagenet_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21674 (21K) [text/plain]\n",
            "Saving to: ‘imagenet_classes.txt.2’\n",
            "\n",
            "\rimagenet_classes.tx   0%[                    ]       0  --.-KB/s               \rimagenet_classes.tx 100%[===================>]  21.17K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-08-09 19:42:37 (17.0 MB/s) - ‘imagenet_classes.txt.2’ saved [21674/21674]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG98TPdDw-7H",
        "outputId": "e5c1fcbd-a550-4915-d694-37da5c7e3a80"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHuZXjA8CCce"
      },
      "source": [
        "with open('imagenet_classes.txt') as f:\n",
        "  classes = [line.strip() for line in f.readlines()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HaYZXs_0RfV",
        "outputId": "2a2d2fdc-323c-4910-a4a3-6b1ee26dcc86"
      },
      "source": [
        "pip install fastapi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.7/dist-packages (0.68.0)\n",
            "Requirement already satisfied: starlette==0.14.2 in /usr/local/lib/python3.7/dist-packages (from fastapi) (0.14.2)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from fastapi) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szo1Hp35zyjP"
      },
      "source": [
        "from colabcode import ColabCode\n",
        "from fastapi import FastAPI\n",
        "import uvicorn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6_ThkgB8sJu"
      },
      "source": [
        "cc=ColabCode(port=12000,code=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bZ2vg638tJ1"
      },
      "source": [
        "import base64\n",
        "from pydantic import BaseModel\n",
        "from PIL import Image\n",
        "\n",
        "class Data(BaseModel):\n",
        "    file: str\n",
        "\n",
        "app=FastAPI()\n",
        "\n",
        "@app.post(\"/classifyimage/\")\n",
        "def classifyimage(image64base : Data):\n",
        "  print(\"in classify\")\n",
        "  if(image64base.file == \"\"): \n",
        "    return [\"False\"]\n",
        "  \n",
        "  with open(\"imageToSave.png\", \"wb\") as fh:\n",
        "    fh.write(base64.b64decode(image64base.file))\n",
        "  img = Image.open(\"imageToSave.png\")\n",
        "\n",
        "  animal_name = get_animal_name(img)\n",
        "  animal_name = animal_name.replace(\" \", \"_\")\n",
        "  animal_name = animal_name.lower()\n",
        "  print(animal_name)\n",
        "  names = animal_name.split(\",_\")\n",
        "  t = Calssify()\n",
        "  return t.classify(names[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbijRF1xwscD"
      },
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "pet = wn.synset('domestic_animal.n.01')\n",
        "#pet = wn.synset('animal.n.01')\n",
        "entity = wn.synset('entity.n.01')\n",
        "bird = wn.synset('bird.n.01')\n",
        "\n",
        "class Animal:\n",
        "    PET  = 1\n",
        "    BIRD = 2\n",
        "    NONE = 3\n",
        "\n",
        "class Calssify:\n",
        "    def __init__(self):\n",
        "        self.found = Animal.NONE\n",
        "         \n",
        "    def _DFSUtil(self,node):\n",
        "        if(node == entity):\n",
        "            self.found = Animal.NONE\n",
        "            return\n",
        "        if(node == bird):\n",
        "            self.found = Animal.BIRD\n",
        "            return\n",
        "        if(node == pet):\n",
        "            self.found = Animal.PET\n",
        "            return               \n",
        "        for neighbour in node.hypernyms():\n",
        "            if node != entity:\n",
        "                self._DFSUtil(neighbour)  \n",
        "\n",
        "    def _DFS(self,node):\n",
        "        self._DFSUtil(node)\n",
        "        return self._printFound()\n",
        "        \n",
        "    def _printFound(self):\n",
        "        if self.found == Animal.PET:\n",
        "            print(\"IT IS A Pet\")\n",
        "            return [\"True\"]\n",
        "        if self.found == Animal.BIRD:\n",
        "            print(\"IT IS A BIRD\")\n",
        "            return [\"True\"]\n",
        "        if self.found == Animal.NONE:\n",
        "            print(\"NOT Domestic Animal\")\n",
        "            return [\"False\"]\n",
        "    \n",
        "    def classify(self,name):\n",
        "        self.found = Animal.NONE\n",
        "        if wn.synsets(name):\n",
        "            print(name)\n",
        "            name = name+\".n.01\"\n",
        "            node = wn.synset(name)\n",
        "            return self._DFS(node)\n",
        "        else:\n",
        "            print(\"NOT Animal\")\n",
        "            return [\"False\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JhOCmHUxVn7",
        "outputId": "acd53f9a-5f22-4bb1-c831-0c1776ec1116"
      },
      "source": [
        "from torchvision import models\n",
        "import torch\n",
        "\n",
        "alexnet = models.alexnet(pretrained=True)\n",
        "print(alexnet)\n",
        "\n",
        "from torchvision import transforms\n",
        "transform = transforms.Compose([            #[1]\n",
        "  #transforms.ToPILImage(),\n",
        " transforms.Resize(256),                    #[2]\n",
        " transforms.CenterCrop(224),                #[3]\n",
        " #transforms.RandomHorizontalFlip(), \n",
        " transforms.ToTensor(),                     #[4]\n",
        " transforms.Normalize(                      #[5]\n",
        " mean=[0.485, 0.456, 0.406],                #[6]\n",
        " std=[0.229, 0.224, 0.225]                  #[7]\n",
        " )])\n",
        "\n",
        "alexnet.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWluOsIWxsR7"
      },
      "source": [
        "def get_animal_name(img):\n",
        "  img_t = transform(img)\n",
        "  batch_t = torch.unsqueeze(img_t, 0)\n",
        "  out = alexnet(batch_t)\n",
        "  print(out.shape)\n",
        "  \n",
        "  _, index = torch.max(out, 1)\n",
        "  #percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "  #print(classes[index[0]], percentage[index[0]].item())\n",
        "  print(classes[index[0]]) \n",
        "  animal_name = classes[index[0]] # we need to convert all letters to lower case and replace spaces with underscore\n",
        "  return animal_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05vt4PzO1qF7",
        "outputId": "c62c6e58-7a18-4447-d694-7a23db5ea279"
      },
      "source": [
        "cc.run_app(app=app)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Public URL: NgrokTunnel: \"https://0190093ae50f.ngrok.io\" -> \"http://localhost:12000\"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [61]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:12000 (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     156.208.228.22:0 - \"POST /classifyimage HTTP/1.1\" 307 Temporary Redirect\n",
            "in classify\n",
            "torch.Size([1, 1000])\n",
            "hen\n",
            "hen\n",
            "hen\n",
            "IT IS A BIRD\n",
            "INFO:     156.208.228.22:0 - \"POST /classifyimage/ HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     156.208.228.22:0 - \"POST /classifyimage HTTP/1.1\" 307 Temporary Redirect\n",
            "in classify\n",
            "torch.Size([1, 1000])\n",
            "lion, king of beasts, Panthera leo\n",
            "lion,_king_of_beasts,_panthera_leo\n",
            "lion\n",
            "NOT Domestic Animal\n",
            "INFO:     156.208.228.22:0 - \"POST /classifyimage/ HTTP/1.1\" 200 OK\n",
            "INFO:     156.208.228.22:0 - \"POST /classifyimage HTTP/1.1\" 307 Temporary Redirect\n",
            "in classify\n",
            "INFO:     156.208.228.22:0 - \"POST /classifyimage/ HTTP/1.1\" 500 Internal Server Error\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 394, in run_asgi\n",
            "    result = await app(self.scope, self.receive, self.send)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/uvicorn/middleware/proxy_headers.py\", line 45, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fastapi/applications.py\", line 208, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/starlette/applications.py\", line 112, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/starlette/middleware/errors.py\", line 181, in __call__\n",
            "    raise exc from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/starlette/middleware/errors.py\", line 159, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/starlette/exceptions.py\", line 82, in __call__\n",
            "    raise exc from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/starlette/exceptions.py\", line 71, in __call__\n",
            "    await self.app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/starlette/routing.py\", line 580, in __call__\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/starlette/routing.py\", line 241, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/starlette/routing.py\", line 52, in app\n",
            "    response = await func(request)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fastapi/routing.py\", line 220, in app\n",
            "    dependant=dependant, values=values, is_coroutine=is_coroutine\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fastapi/routing.py\", line 154, in run_endpoint_function\n",
            "    return await run_in_threadpool(dependant.call, **values)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/starlette/concurrency.py\", line 40, in run_in_threadpool\n",
            "    return await loop.run_in_executor(None, func, *args)\n",
            "  File \"/usr/lib/python3.7/asyncio/futures.py\", line 263, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "  File \"/usr/lib/python3.7/asyncio/tasks.py\", line 318, in __wakeup\n",
            "    future.result()\n",
            "  File \"/usr/lib/python3.7/asyncio/futures.py\", line 181, in result\n",
            "    raise self._exception\n",
            "  File \"/usr/lib/python3.7/concurrent/futures/thread.py\", line 57, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"<ipython-input-82-8da4c338e753>\", line 26, in classifyimage\n",
            "    img = Image.open(\"imageToSave.png\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2896, in open\n",
            "    \"cannot identify image file %r\" % (filename if filename else fp)\n",
            "PIL.UnidentifiedImageError: cannot identify image file 'imageToSave.png'\n",
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [61]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZNslgG9WX7a",
        "outputId": "8d22f2fb-4cfe-4a8b-cf1b-e8e9d011ebcf"
      },
      "source": [
        "import json\n",
        "x =  '{ \"name\":\"John\", \"age\":30, \"city\":\"New York\"}'\n",
        "x = '{\"base46\":\"content in the file\"}'\n",
        "y = json.loads(x)\n",
        "print(y[\"base46\"]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "content in the file\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}